{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67595</th>\n",
       "      <td>SEC charges two ICO operators with fraud</td>\n",
       "      <td>The US Securities and Exchange Commission (SEC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73705</th>\n",
       "      <td>75-yr-old falls off 21st floor of building nea...</td>\n",
       "      <td>A 75-year-old man died on Thursday morning aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55460</th>\n",
       "      <td>Man begging found with FD of Ã¢ÂÂ¹1cr, turns ...</td>\n",
       "      <td>A beggar living in Uttar Pradesh's Raebareli w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13157</th>\n",
       "      <td>Two Maharashtra inter-city trains start 'Libra...</td>\n",
       "      <td>The monthly ticket holders of two popular Maha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70715</th>\n",
       "      <td>Madras HC dismisses plea against AIADMK Genera...</td>\n",
       "      <td>Madras High Court has dismissed a petition by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7344</th>\n",
       "      <td>Marriage was on my mind but it did not work ou...</td>\n",
       "      <td>Katrina Kaif, on being asked if marriage is on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21848</th>\n",
       "      <td>2 arrested for allegedly planning attack on IS...</td>\n",
       "      <td>National Investigation Agency (NIA) on Sunday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68649</th>\n",
       "      <td>Brexit may give rise to new 'Euro-English' lan...</td>\n",
       "      <td>A study has claimed that Brexit may pave way f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31744</th>\n",
       "      <td>'Bhangra Ta Sajda' song from 'Veere Di Wedding...</td>\n",
       "      <td>A new song titled 'Bhangra Ta Sajda' from Sona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84822</th>\n",
       "      <td>Chennai Police road safety video asks parents ...</td>\n",
       "      <td>Police officers in Chennai have released a roa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "67595          SEC charges two ICO operators with fraud    \n",
       "73705  75-yr-old falls off 21st floor of building nea...   \n",
       "55460  Man begging found with FD of Ã¢ÂÂ¹1cr, turns ...   \n",
       "13157  Two Maharashtra inter-city trains start 'Libra...   \n",
       "70715  Madras HC dismisses plea against AIADMK Genera...   \n",
       "7344   Marriage was on my mind but it did not work ou...   \n",
       "21848  2 arrested for allegedly planning attack on IS...   \n",
       "68649  Brexit may give rise to new 'Euro-English' lan...   \n",
       "31744  'Bhangra Ta Sajda' song from 'Veere Di Wedding...   \n",
       "84822  Chennai Police road safety video asks parents ...   \n",
       "\n",
       "                                                    text  \n",
       "67595  The US Securities and Exchange Commission (SEC...  \n",
       "73705  A 75-year-old man died on Thursday morning aft...  \n",
       "55460  A beggar living in Uttar Pradesh's Raebareli w...  \n",
       "13157  The monthly ticket holders of two popular Maha...  \n",
       "70715  Madras High Court has dismissed a petition by ...  \n",
       "7344   Katrina Kaif, on being asked if marriage is on...  \n",
       "21848  National Investigation Agency (NIA) on Sunday ...  \n",
       "68649  A study has claimed that Brexit may pave way f...  \n",
       "31744  A new song titled 'Bhangra Ta Sajda' from Sona...  \n",
       "84822  Police officers in Chennai have released a roa...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98401, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98280\n",
      "98360\n"
     ]
    }
   ],
   "source": [
    "print(data['headlines'].nunique())\n",
    "print(data['text'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data['headlines'].isnull().sum())\n",
    "print(data['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Warne rightly predicted India-Eng 2011 WC match to be a tie          3\n",
       "Why is England-Australia Test series called 'The Ashes'?             3\n",
       "Warne produced 'ball of century' with his 1st Ashes delivery         3\n",
       "Don Bradman once scored 100 runs in 3 overs                          3\n",
       "CARS24 enables car owners to sell their cars in less than 2 hours    3\n",
       "                                                                    ..\n",
       "Chandigarh stalking accused's bail rejected for 4th time             1\n",
       " Daughter of woman rescued from Saudi thanks Sushma Swaraj           1\n",
       "MP candidate polishes voters' shoes to please them ahead of polls    1\n",
       "I'm 1st US President to know how to make daal: Barack Obama          1\n",
       "Fearing encounter, UP criminals sell fruits, repair bicycles         1\n",
       "Name: headlines, Length: 98280, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['headlines'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17603</th>\n",
       "      <td>Warne rightly predicted India-Eng 2011 WC matc...</td>\n",
       "      <td>Before India-England 2011 World Cup match, for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45940</th>\n",
       "      <td>Warne rightly predicted India-Eng 2011 WC matc...</td>\n",
       "      <td>Before India-England's 2011 World Cup match on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70392</th>\n",
       "      <td>Warne rightly predicted India-Eng 2011 WC matc...</td>\n",
       "      <td>Before India-England 2011 World Cup match, for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "17603  Warne rightly predicted India-Eng 2011 WC matc...   \n",
       "45940  Warne rightly predicted India-Eng 2011 WC matc...   \n",
       "70392  Warne rightly predicted India-Eng 2011 WC matc...   \n",
       "\n",
       "                                                    text  \n",
       "17603  Before India-England 2011 World Cup match, for...  \n",
       "45940  Before India-England's 2011 World Cup match on...  \n",
       "70392  Before India-England 2011 World Cup match, for...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['headlines'] == 'Warne rightly predicted India-Eng 2011 WC match to be a tie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(keep = 'first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98379, 2)\n",
      "headlines    98280\n",
      "text         98360\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                                headlines  \\\n",
       "0      upGrad learner switches to career in ML & Al w...   \n",
       "1      Delhi techie wins free food from Swiggy for on...   \n",
       "2      New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3      Aegon life iTerm insurance plan helps customer...   \n",
       "4      Have known Hirani for yrs, what if MeToo claim...   \n",
       "...                                                  ...   \n",
       "98396  CRPF jawan axed to death by Maoists in Chhatti...   \n",
       "98397  First song from Sonakshi Sinha's 'Noor' titled...   \n",
       "98398         'The Matrix' film to get a reboot: Reports   \n",
       "98399  Snoop Dogg aims gun at clown dressed as Trump ...   \n",
       "98400  Madhesi Morcha withdraws support to Nepalese g...   \n",
       "\n",
       "                                                    text  \n",
       "0      Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1      Kunal Shah's credit card bill payment platform...  \n",
       "2      New Zealand defeated India by 8 wickets in the...  \n",
       "3      With Aegon Life iTerm Insurance plan, customer...  \n",
       "4      Speaking about the sexual harassment allegatio...  \n",
       "...                                                  ...  \n",
       "98396  A CRPF jawan was on Tuesday axed to death with...  \n",
       "98397  'Uff Yeh', the first song from the Sonakshi Si...  \n",
       "98398  According to reports, a new version of the 199...  \n",
       "98399  A new music video shows rapper Snoop Dogg aimi...  \n",
       "98400  Madhesi Morcha, an alliance of seven political...  \n",
       "\n",
       "[98379 rows x 2 columns]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (headlines)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp   # 멀티 프로세싱으로 전처리 속도를 획기적으로 줄여봅시다\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  # map을 할 때 함수에 여러 인자를 넣어줄 수 있도록 합니다\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores 만큼 쪼개진 데이터를 전처리하여 반환합니다\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "  texts = []\n",
    "  for s in sentences:\n",
    "    texts += preprocess_sentence(s, remove_stopwords),\n",
    "  return texts\n",
    "\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "  start_time = time.time()\n",
    "  num_cores = mp.cpu_count()  # 컴퓨터의 코어 수를 구합니다\n",
    "\n",
    "  text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬적으로 처리할 수 있게 합니다\n",
    "  pool = Pool(num_cores)\n",
    "\n",
    "  processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split))  # 각자 작업한 데이터를 하나로 합쳐줍니다\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(time.time() - start_time, \" seconds\")\n",
    "  return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424.8778693675995  seconds\n",
      "13.5986487865448  seconds\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-972851b3bf3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclean_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclean_headlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headlines'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_headlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "clean_text = preprocess_data(data['text'])\n",
    "clean_headlines = preprocess_data(data['headlines'], remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers'\n",
      " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit'\n",
      " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history'\n",
      " ...\n",
      " 'according reports new version science fiction film matrix development michael jordan reportedly play lead role film screenwriter zak penn talks write script film reports added actor keanu reeves starred original film followed two sequels'\n",
      " 'new music video shows rapper snoop dogg aiming toy gun clown character parodying us president donald trump video also shows tv airing news conference headline ronald klump wants deport doggs airing live clown house video remixed version song lavender'\n",
      " 'madhesi morcha alliance seven political parties withdrawn support pm pushpa kamal dahal led nepal government failed meet seven day ultimatum fulfil demands including endorsement revised constitution amendment bill morcha seats parliament despite withdrawal support immediate threat government']\n",
      "['upgrad learner switches to career in ml al with salary hike'\n",
      " 'delhi techie wins free food from swiggy for one year on cred'\n",
      " 'new zealand end rohit sharma led india match winning streak' ...\n",
      " 'the matrix film to get reboot reports'\n",
      " 'snoop dogg aims gun at clown dressed as trump in new video'\n",
      " 'madhesi morcha withdraws support to nepalese government']\n"
     ]
    }
   ],
   "source": [
    "print(clean_text)\n",
    "print(clean_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 40\n",
    "headlines_max_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 40 이하인 샘플의 비율: 0.9238557009117799\n",
      "전체 샘플 중 길이가 10 이하인 샘플의 비율: 0.8162920948576424\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 74115\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시작종료 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "      <td>pakistani singer rahat fateh ali khan denied r...</td>\n",
       "      <td>sostoken rahat fateh ali khan denies getting n...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cong wins ramgarh bypoll in rajasthan takes to...</td>\n",
       "      <td>congress candidate shafia zubair ramgarh assem...</td>\n",
       "      <td>sostoken cong wins ramgarh bypoll in rajasthan...</td>\n",
       "      <td>cong wins ramgarh bypoll in rajasthan takes to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>up cousins fed human excreta for friendship wi...</td>\n",
       "      <td>two minor cousins uttar pradesh gorakhpur alle...</td>\n",
       "      <td>sostoken up cousins fed human excreta for frie...</td>\n",
       "      <td>up cousins fed human excreta for friendship wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headlines  \\\n",
       "2   new zealand end rohit sharma led india match w...   \n",
       "3   aegon life iterm insurance plan helps customer...   \n",
       "5   rahat fateh ali khan denies getting notice for...   \n",
       "9   cong wins ramgarh bypoll in rajasthan takes to...   \n",
       "10  up cousins fed human excreta for friendship wi...   \n",
       "\n",
       "                                                 text  \\\n",
       "2   new zealand defeated india wickets fourth odi ...   \n",
       "3   aegon life iterm insurance plan customers enjo...   \n",
       "5   pakistani singer rahat fateh ali khan denied r...   \n",
       "9   congress candidate shafia zubair ramgarh assem...   \n",
       "10  two minor cousins uttar pradesh gorakhpur alle...   \n",
       "\n",
       "                                        decoder_input  \\\n",
       "2   sostoken new zealand end rohit sharma led indi...   \n",
       "3   sostoken aegon life iterm insurance plan helps...   \n",
       "5   sostoken rahat fateh ali khan denies getting n...   \n",
       "9   sostoken cong wins ramgarh bypoll in rajasthan...   \n",
       "10  sostoken up cousins fed human excreta for frie...   \n",
       "\n",
       "                                       decoder_target  \n",
       "2   new zealand end rohit sharma led india match w...  \n",
       "3   aegon life iterm insurance plan helps customer...  \n",
       "5   rahat fateh ali khan denies getting notice for...  \n",
       "9   cong wins ramgarh bypoll in rajasthan takes to...  \n",
       "10  up cousins fed human excreta for friendship wi...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8673 74029 65778 ... 24447 39645 29635]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 14823\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 59292\n",
      "훈련 레이블의 개수 : 59292\n",
      "테스트 데이터의 개수 : 14823\n",
      "테스트 레이블의 개수 : 14823\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 61741\n",
      "등장 빈도가 9번 이하인 희귀 단어의 수: 45828\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 15913\n",
      "단어 집합에서 희귀 단어의 비율: 74.2262030093455\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.519649027645804\n"
     ]
    }
   ],
   "source": [
    "threshold = 10\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어집합 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 16000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[588, 2, 15, 1659, 179, 819, 46, 453, 649, 27, 8, 153, 1531, 581, 1027, 27, 15914, 172, 390, 14, 6768, 9751, 27, 47, 51, 2582, 3232, 93, 1274, 1016, 10022, 75, 265, 611, 206, 238, 153, 9751, 6654], [181, 14, 145, 71, 50, 93, 3422, 827, 3815, 254, 13, 129, 214, 1, 71, 951, 71, 1239, 52, 93, 18, 9246, 15915, 81, 149, 1, 5995, 1692], [498, 12667, 2482, 262, 1275, 14388, 2569, 5322, 582, 860, 15916, 44, 28, 158, 12667, 331, 167, 2, 15, 920, 445, 357, 1111, 1209, 212, 327, 8840, 186, 12668, 498, 15917, 1275, 871, 703, 328, 247, 4038]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## headlines 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 27342\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 19114\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8228\n",
      "단어 집합에서 희귀 단어의 비율: 69.90710262599663\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.840436156958845\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 34, 33, 1022, 1121, 12, 265, 6495], [1, 42, 1287, 3, 20, 27, 3221, 5, 117, 473], [1, 4127, 161, 1436, 8, 4877, 450, 3014], [1, 3698, 93, 1109, 120, 60, 1629, 4, 9], [1, 917, 5, 136, 1097, 84]]\n",
      "target\n",
      "decoder  [[34, 33, 1022, 1121, 12, 265, 6495, 2], [42, 1287, 3, 20, 27, 3221, 5, 117, 473, 2], [4127, 161, 1436, 8, 4877, 450, 3014, 2], [3698, 93, 1109, 120, 60, 1629, 4, 9, 2], [917, 5, 136, 1097, 84, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 8000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 삭제된 단어에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 59291\n",
      "훈련 레이블의 개수 : 59291\n",
      "테스트 데이터의 개수 : 14823\n",
      "테스트 레이블의 개수 : 14823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패딩추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 128)      2048000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 40, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 40, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1024000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 40, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8000)   2056000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,967,104\n",
      "Trainable params: 6,967,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 128)      2048000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 40, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 40, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1024000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 40, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 8000)   4104000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 9,146,432\n",
      "Trainable params: 9,146,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "232/232 [==============================] - 60s 222ms/step - loss: 6.5549 - val_loss: 5.7538\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 5.7340 - val_loss: 5.4604\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 5.3923 - val_loss: 5.1943\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 5.1026 - val_loss: 4.9601\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 4.8476 - val_loss: 4.7836\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 4.6149 - val_loss: 4.6349\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 4.4284 - val_loss: 4.5288\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 4.2519 - val_loss: 4.4529\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 4.1140 - val_loss: 4.3697\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 3.9807 - val_loss: 4.3204\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 3.8639 - val_loss: 4.2619\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 3.7531 - val_loss: 4.2299\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 51s 218ms/step - loss: 3.6520 - val_loss: 4.1991\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 3.5528 - val_loss: 4.1795\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 50s 217ms/step - loss: 3.4672 - val_loss: 4.1441\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 3.3972 - val_loss: 4.1263\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 51s 218ms/step - loss: 3.3172 - val_loss: 4.1215\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 3.2435 - val_loss: 4.1074\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 3.1751 - val_loss: 4.1028\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 3.1032 - val_loss: 4.0936\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 50s 217ms/step - loss: 3.0539 - val_loss: 4.0929\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 2.9944 - val_loss: 4.0903\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 2.9350 - val_loss: 4.0937\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 50s 216ms/step - loss: 2.8893 - val_loss: 4.0921\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 51s 218ms/step - loss: 2.8347 - val_loss: 4.0920\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : payments startup mobikwik raised nearly crore bridge round led sequoia capital contribution crore according report two existing investors net venture partners reportedly also participated round comes mobikwik talks raise nearly crore last year \n",
      "실제 요약 : mobikwik raises cr in bridge round led by sequoia report \n",
      "예측 요약 :  raises crore from december\n",
      "\n",
      "\n",
      "원문 : actress priyanka chopra production little visitors screened ongoing toronto international film festival earlier film first look unveiled cannes film festival actress also took part fest new segment share journey discussed career work outside entertainment industry \n",
      "실제 요약 : priyanka production screened at fest \n",
      "예측 요약 :  priyanka chopra to perform at cannes festival festival\n",
      "\n",
      "\n",
      "원문 : sardar local bjp leader west bengal died friday night allegedly attacked goons sharp weapon kolkata mandir bazar returning home west bengal bjp accused trinamool congress incident tweeted continuation panchayat poll violence process panchayat board begun \n",
      "실제 요약 : bjp leader dies after allegedly being attacked by \n",
      "예측 요약 :  bjp leader dies in stone pelting near bengal\n",
      "\n",
      "\n",
      "원문 : year old australian boy admitted hacking world valuable company apple servers internal files fan apple wanted work one day stored gb hacked data titled hack hack boy pleaded guilty return court sentencing september \n",
      "실제 요약 : year old apple fan admits to hacking the company \n",
      "예측 요약 :  yr old apple apple apple iphone lawsuit\n",
      "\n",
      "\n",
      "원문 : former captain rahul dravid appointed india batting consultant overseas tours bcci announced tuesday dravid would take role alongside current position coach india teams recently given two year extension dravid appointed alongside ravi shastri head coach zaheer khan bowling coach \n",
      "실제 요약 : dravid to be india batting for overseas \n",
      "예측 요약 :  india best team of india coach dravid dravid\n",
      "\n",
      "\n",
      "원문 : ratan tata chairman emeritus tata sons share stage rss chief mohan bhagwat event mumbai rss official said event organised ngo affiliated rss reportedly take place august comes former president pranab mukherjee addressed event rss headquarters nagpur last month \n",
      "실제 요약 : ratan tata to share stage with rss chief mohan bhagwat \n",
      "예측 요약 :  tata motors md quits as president\n",
      "\n",
      "\n",
      "원문 : actress prakash comparing tv show piya ki game thrones said people love game thrones thing happens piya ki issue talking show added think really progressive people believe judging book cover \n",
      "실제 요약 : pehredaar piya ki actress compares show to game of thrones \n",
      "예측 요약 :  am not to do not much alia on alia\n",
      "\n",
      "\n",
      "원문 : government said early give legal backing agreements feasibility needs assessed meeting many expressed agreements might women rights personal laws agreement pre marital contract details property division rights case divorce \n",
      "실제 요약 : too early to give agreement legal backing govt \n",
      "예측 요약 :  cannot change eu channels to maintain content govt\n",
      "\n",
      "\n",
      "원문 : railways started installing wires seal illegal entry exit points railway premises across mumbai stop people crossing tracks decision taken found around commuters die local railway network annually deaths take place commuters cross tracks \n",
      "실제 요약 : mumbai stations get to stop track crossing \n",
      "예측 요약 :  mumbai civic body to get new coaches\n",
      "\n",
      "\n",
      "원문 : facebook moved database billion users international headquarters ireland us comes ahead new data privacy law due come force europe new law facebook liable pay fines global turnover breaking data protection rules \n",
      "실제 요약 : facebook moves database of bn users from ireland to us \n",
      "예측 요약 :  facebook facebook facebook over china over illegal\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 60):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
