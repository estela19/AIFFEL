{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows=100000)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17723</th>\n",
       "      <td>My hubby considers himself a hot sauce expert....</td>\n",
       "      <td>We love Tenessee Red Lightnin'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11937</th>\n",
       "      <td>These aren't grandma's cookies, but tasty enou...</td>\n",
       "      <td>Good quick snack or breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73361</th>\n",
       "      <td>I've been craving some good taffy for a while,...</td>\n",
       "      <td>No thanks....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72674</th>\n",
       "      <td>My dogs eat just about anything, but only 1 of...</td>\n",
       "      <td>2 stars for a 20% product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74682</th>\n",
       "      <td>Great product.  My dog loves the bones and the...</td>\n",
       "      <td>My dog loves them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41528</th>\n",
       "      <td>These are my Yorkipoo and Shih-Tzu's favorite ...</td>\n",
       "      <td>My toy dogs LOVE these treats!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36058</th>\n",
       "      <td>We have looked far and wide for a gluten free ...</td>\n",
       "      <td>the best pizza crust mix ever!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45665</th>\n",
       "      <td>As a hot drink, this made a great alternative ...</td>\n",
       "      <td>Tasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>I ordered this Pack of 20 1-pound full leaf te...</td>\n",
       "      <td>Not full leaf, 1 pound, not 20 pounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903</th>\n",
       "      <td>Unlike another product I reviewed for Vine, at...</td>\n",
       "      <td>Questionable \"healthy\" drink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13482</th>\n",
       "      <td>its more expensive than the rest but let me te...</td>\n",
       "      <td>love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8769</th>\n",
       "      <td>Awesome!  This powder was bought as a media re...</td>\n",
       "      <td>Agar Powder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>I like this product so much I have it delivere...</td>\n",
       "      <td>Refreshing and Delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31417</th>\n",
       "      <td>Carefull!  Although the picture shows a BOX of...</td>\n",
       "      <td>$4.95 a pack?!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67615</th>\n",
       "      <td>This coffee is delicious and a great price too...</td>\n",
       "      <td>Chocolate Glazed Donut K Cup Coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "17723  My hubby considers himself a hot sauce expert....   \n",
       "11937  These aren't grandma's cookies, but tasty enou...   \n",
       "73361  I've been craving some good taffy for a while,...   \n",
       "72674  My dogs eat just about anything, but only 1 of...   \n",
       "74682  Great product.  My dog loves the bones and the...   \n",
       "41528  These are my Yorkipoo and Shih-Tzu's favorite ...   \n",
       "36058  We have looked far and wide for a gluten free ...   \n",
       "45665  As a hot drink, this made a great alternative ...   \n",
       "2809   I ordered this Pack of 20 1-pound full leaf te...   \n",
       "6903   Unlike another product I reviewed for Vine, at...   \n",
       "13482  its more expensive than the rest but let me te...   \n",
       "8769   Awesome!  This powder was bought as a media re...   \n",
       "2835   I like this product so much I have it delivere...   \n",
       "31417  Carefull!  Although the picture shows a BOX of...   \n",
       "67615  This coffee is delicious and a great price too...   \n",
       "\n",
       "                                     Summary  \n",
       "17723         We love Tenessee Red Lightnin'  \n",
       "11937          Good quick snack or breakfast  \n",
       "73361                          No thanks....  \n",
       "72674              2 stars for a 20% product  \n",
       "74682                      My dog loves them  \n",
       "41528         My toy dogs LOVE these treats!  \n",
       "36058       the best pizza crust mix ever!!!  \n",
       "45665                                  Tasty  \n",
       "2809   Not full leaf, 1 pound, not 20 pounds  \n",
       "6903         Questionable \"healthy\" drink...  \n",
       "13482                                love it  \n",
       "8769                             Agar Powder  \n",
       "2835                Refreshing and Delicious  \n",
       "31417                     $4.95 a pack?!!!!!  \n",
       "67615    Chocolate Glazed Donut K Cup Coffee  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Text','Summary']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복과 NULL 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['Text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>Not as Advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>Cough Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary\n",
       "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
       "2  This is a confection that has been around a fe...  \"Delight\" says it all\n",
       "3  If you are looking for the secret ingredient i...         Cough Medicine\n",
       "4  Great taffy at a great price.  There was a wid...            Great taffy"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.isnull().sum())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트 정규화 & 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "멀티프로세싱을 이용한 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546.310090303421  seconds\n",
      "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better'\n",
      " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo'\n",
      " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch'\n",
      " ...\n",
      " 'favorite brand korean ramen spicy used eating spicy food make sure use spice pack add egg soup makes great snack'\n",
      " 'like noodles although say spicy somewhat understatement one else family tolerates spicy well seeing looking forward extra little something palate disappointed completely honest usually drain liquid almost much'\n",
      " 'love noodle twice week amazing thing feel well cold hot bowl noodle cure upset stomach headache running nose may work definitely try']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/b007i7yygy/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.168606281280518  seconds\n",
      "['good quality dog food' 'not as advertised' 'delight says it all' ...\n",
      " 'great ramen' 'spicy'\n",
      " 'this spicy noodle cures my cold upset stomach and headache every time']\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp   # 멀티 프로세싱으로 전처리 속도를 획기적으로 줄여봅시다\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  # map을 할 때 함수에 여러 인자를 넣어줄 수 있도록 합니다\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores 만큼 쪼개진 데이터를 전처리하여 반환합니다\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "  texts = []\n",
    "  for s in sentences:\n",
    "    texts += preprocess_sentence(s, remove_stopwords),\n",
    "  return texts\n",
    "\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "  start_time = time.time()\n",
    "  num_cores = mp.cpu_count()  # 컴퓨터의 코어 수를 구합니다\n",
    "\n",
    "  text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬적으로 처리할 수 있게 합니다\n",
    "  pool = Pool(num_cores)\n",
    "\n",
    "  processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split))  # 각자 작업한 데이터를 하나로 합쳐줍니다\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(time.time() - start_time, \" seconds\")\n",
    "  return processed_data\n",
    "\n",
    "clean_text = preprocess_data(data['Text'])  # 클라우드 기준으로 3~4분 정도 소요 됩니다\n",
    "print(clean_text)\n",
    "\n",
    "clean_summary = preprocess_data(data['Summary'], remove_stopwords=False) # 클라우드 기준 1분정도 소요됩니다.\n",
    "print(clean_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불용어 제거후 빈 샘플 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'quality', 'dog', 'food']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = data['Summary'][0]\n",
    "s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시작토큰과 종료토큰 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플 섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26860  1796  5152 ...  6923  4897 14571]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 집합 만들기 및 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "낮은 빈도수 단어 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 31963\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23719\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8244\n",
      "단어 집합에서 희귀 단어의 비율: 74.20767762725652\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.3861869319339757\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어집합 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34, 162, 1018, 14, 115, 185, 162, 166, 375, 159, 1283, 619, 445, 9, 1973, 244, 246, 94, 185, 162, 117, 37, 45, 250], [6, 755, 1013, 7, 57, 1438, 273, 34, 61, 250, 57, 78, 1438, 273, 232, 2146, 61, 2305, 66, 869, 230, 1195, 232, 2146, 62, 28, 3, 224], [882, 44, 157, 1314, 9, 1252, 12, 4, 1, 2970, 2886, 44, 61, 125, 199, 12, 234, 65, 3, 365, 6171, 384, 1409, 17, 44]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary데이터에도 동일한 작업 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10522\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8131\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2391\n",
      "단어 집합에서 희귀 단어의 비율: 77.27618323512641\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.897980185060001\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 318, 1358, 240], [1, 5, 8, 51, 1663], [1, 59, 31, 1097], [1, 38, 58, 10, 98, 64, 223], [1, 247]]\n",
      "target\n",
      "decoder  [[318, 1358, 240, 2], [5, 8, 51, 1663, 2], [59, 31, 1097, 2], [38, 58, 10, 98, 64, 223, 2], [247, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빈도가 낮은 단어로만 구성되어서 null이 된 데이터 삭제.\n",
    "bos, eos 토큰만 남아있을 것이므로 sentence len 이 1이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1278\n",
      "삭제할 테스트 데이터의 개수 : 341\n",
      "훈련 데이터의 개수 : 51377\n",
      "훈련 레이블의 개수 : 51377\n",
      "테스트 데이터의 개수 : 12822\n",
      "테스트 레이블의 개수 : 12822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패딩추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어텐션 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 52s 209ms/step - loss: 3.1328 - val_loss: 2.4326\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 40s 200ms/step - loss: 2.4166 - val_loss: 2.3088\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 41s 202ms/step - loss: 2.2801 - val_loss: 2.1665\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 41s 204ms/step - loss: 2.1356 - val_loss: 2.0743\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 41s 202ms/step - loss: 2.0418 - val_loss: 2.0177\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 42s 209ms/step - loss: 1.9583 - val_loss: 1.9772\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 43s 213ms/step - loss: 1.9018 - val_loss: 1.9498\n",
      "Epoch 8/50\n",
      "201/201 [==============================] - 42s 210ms/step - loss: 1.8502 - val_loss: 1.9222\n",
      "Epoch 9/50\n",
      "201/201 [==============================] - 41s 203ms/step - loss: 1.8104 - val_loss: 1.9101\n",
      "Epoch 10/50\n",
      "201/201 [==============================] - 41s 202ms/step - loss: 1.7773 - val_loss: 1.8917\n",
      "Epoch 11/50\n",
      "201/201 [==============================] - 41s 202ms/step - loss: 1.7323 - val_loss: 1.8900\n",
      "Epoch 12/50\n",
      "201/201 [==============================] - 41s 203ms/step - loss: 1.7050 - val_loss: 1.8728\n",
      "Epoch 13/50\n",
      "201/201 [==============================] - 40s 201ms/step - loss: 1.6697 - val_loss: 1.8710\n",
      "Epoch 14/50\n",
      "201/201 [==============================] - 40s 201ms/step - loss: 1.6461 - val_loss: 1.8656\n",
      "Epoch 15/50\n",
      "201/201 [==============================] - 43s 213ms/step - loss: 1.6137 - val_loss: 1.8724\n",
      "Epoch 16/50\n",
      "201/201 [==============================] - 43s 216ms/step - loss: 1.5815 - val_loss: 1.8619\n",
      "Epoch 17/50\n",
      "201/201 [==============================] - 43s 212ms/step - loss: 1.5575 - val_loss: 1.8610\n",
      "Epoch 18/50\n",
      "201/201 [==============================] - 41s 205ms/step - loss: 1.5320 - val_loss: 1.8604\n",
      "Epoch 19/50\n",
      "201/201 [==============================] - 40s 201ms/step - loss: 1.4993 - val_loss: 1.8613\n",
      "Epoch 20/50\n",
      "201/201 [==============================] - 40s 201ms/step - loss: 1.4803 - val_loss: 1.8660\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "복원을 위한 사전 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인퍼런스 단계에서 단어 시퀀스를 완성하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : much good thing worked kibble time slowly percentage national junk food brand bowl natural time cats could keep mess moved \n",
      "실제 요약 : the cats \n",
      "예측 요약 :  my cats love it\n",
      "\n",
      "\n",
      "원문 : good brings back old times problem wafers thinner slightly harder remember close get idea chocolate drops top colorful foil cardboard tube still brings back nice memories \n",
      "실제 요약 : good \n",
      "예측 요약 :  great chocolate\n",
      "\n",
      "\n",
      "원문 : cheez best cheese cracker market today superior goldfish always superior cheese strongest flavor brand market \n",
      "실제 요약 : cheez it all \n",
      "예측 요약 :  best cheese crackers ever\n",
      "\n",
      "\n",
      "원문 : dog years old product part wonderful walks like yrs old thanks \n",
      "실제 요약 : wonderful natural product for older dogs \n",
      "예측 요약 :  dog loves it\n",
      "\n",
      "\n",
      "원문 : tried tea introduction rooibos excited hearing benefits rooibos dissapointment thought tea disgusting luckily give tried brands rooibos fantastic tea stale vanilla taste completely covers natural flavor rooibos stay away tea plain rooibos without added flavors perfect \n",
      "실제 요약 : worst rooibos \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : coombs family farms organic maple syrup best market sweet clear smooth amazon price beats local health food store every time stock use lovely sweetener nice flavor twist stores great shelf put fridge opening keeps well fridge \n",
      "실제 요약 : chef \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : dried chicken breasts healthy treat expensive dogs get day happy hips bag grocery pet stores bags real deal worth \n",
      "실제 요약 : dogs love \n",
      "예측 요약 :  my dogs love these treats\n",
      "\n",
      "\n",
      "원문 : doggie goes crazy hears box opened sensitive teeth doesnt like hard stuff perfect started using getting teeth cleaned give one every days keeping teeth clean \n",
      "실제 요약 : my doggie hates everything but loves these \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : dare cookies made peanut tree nut free factory canada super yummy impossible find texas hope amazon continues carry dare maple cookies good \n",
      "실제 요약 : my son favorite \n",
      "예측 요약 :  the best\n",
      "\n",
      "\n",
      "원문 : popcorn pop much taste get seasoning salt something see tastes poured butter defeats idea diet stuff \n",
      "실제 요약 : popcorn \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : son loves happy baby pouches like share like organic smoothies banana beet blueberry great flavor combination \n",
      "실제 요약 : delicious for moms too \n",
      "예측 요약 :  great for\n",
      "\n",
      "\n",
      "원문 : ordered syrup christmas amazon found tasty quick shipment fair price good buy \n",
      "실제 요약 : maple syrup \n",
      "예측 요약 :  great syrup\n",
      "\n",
      "\n",
      "원문 : sans black cherry soda best tasting diet soda tried sweetener herb stevia natural calories sugar great refreshing drink \n",
      "실제 요약 : healthy \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : cereal normally health food stores live keep buying cereal worth found amazon great price bought box deal stocked months reduced cost groceries thanks amazon \n",
      "실제 요약 : love the cereal love the amazon com price \n",
      "예측 요약 :  great cereal\n",
      "\n",
      "\n",
      "원문 : delicious co worker bringing work daily found stealing several pieces throughout day stash finally decided buy bag steal change yummy addictive nutritious eat moderation forewarned pop fun stop \n",
      "실제 요약 : yum \n",
      "예측 요약 :  the best\n",
      "\n",
      "\n",
      "원문 : second time bought cherry jolly rancher sticks happy orders cheapest found anywhere internet shipped new jersey state sent takes like days get sticks big enough break pieces open like regular jolly rancher size flat spread instead round tube like like cherry best get price exact taste enjoy \n",
      "실제 요약 : sticks cherry \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : tastes exactly like samoas bomb love new favorite weeks ago ate entire box samoas diet watching eat little make feel really bad like ate box samoas however calories perfect fiber fills yummy \n",
      "실제 요약 : delicious \n",
      "예측 요약 :  the best\n",
      "\n",
      "\n",
      "원문 : great tasting sweetener compared sugar calories give us stomach aches like artificial sweeteners often sodastream managed kick day coke habit coke something tasty fizzy drink liters day subscription two bottles month use new one comes \n",
      "실제 요약 : great tasting sweetener \n",
      "예측 요약 :  great stuff\n",
      "\n",
      "\n",
      "원문 : love hazelnuts hazelnut spreads thought seems competition still far behind nutella getting right taste reason bought product american trans fats obviously wanted avoid sold amazon european ones least german versions hazelnut spread sweet liking bad small change never buy product nutella especially price \n",
      "실제 요약 : not killer \n",
      "예측 요약 :  the best thing ever\n",
      "\n",
      "\n",
      "원문 : great product sure good skin types basically natural product mask great feels cool soothing little goes long way used times cannot tell look least yet recommend products good price site \n",
      "실제 요약 : love this \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : great product give one dental chew day dog loves helps maintain great teeth every time go vet hear positive feedback maintenance helps avoid expensive \n",
      "실제 요약 : my dog loves these dental chews \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : disappointed expensive one flower per oz cup still weak flower pretty \n",
      "실제 요약 : weak \n",
      "예측 요약 :  not what expected\n",
      "\n",
      "\n",
      "원문 : love pamela baking mix used make pancakes makes best gf pancakes \n",
      "실제 요약 : great product \n",
      "예측 요약 :  best bread mix ever\n",
      "\n",
      "\n",
      "원문 : like iced chai powder small amount hot water add ice milk yum \n",
      "실제 요약 : best chai on the market \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : product worth anything threw used past flavored oils product terrible \n",
      "실제 요약 : bad product \n",
      "예측 요약 :  horrible\n",
      "\n",
      "\n",
      "원문 : dog walk away rawhide loves like help clean teeth vet says great shape nine year old \n",
      "실제 요약 : my dog loves these \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : like mean see butterscotch stick kind great book butterscotch stick get anything sticky heaven delicious try \n",
      "실제 요약 : on stick oh my \n",
      "예측 요약 :  best ever\n",
      "\n",
      "\n",
      "원문 : shih tzu seven one greenie day years happy healthy great teeth begs greenie every morning worry greenies causing allergies main source allergies corn dog food little one favor go grain free reduced grain dog food think wild dogs eat corn meal little one allergies amazed immediate healing \n",
      "실제 요약 : wonderful treat \n",
      "예측 요약 :  great value for greenies dogs\n",
      "\n",
      "\n",
      "원문 : exactly looking even better perfect even better raw thank making product \n",
      "실제 요약 : perfect \n",
      "예측 요약 :  great\n",
      "\n",
      "\n",
      "원문 : like old fashioned animal cookie taste want taste subtle hint chocolate family member tried cookies calories quite satisfying curb sweet tooth wish could give product ten stars \n",
      "실제 요약 : stars \n",
      "예측 요약 :  yummy\n",
      "\n",
      "\n",
      "원문 : add water peanut butter stuff tastes great banana peanut butter without fat would ever thought \n",
      "실제 요약 : great product great price and healthy to \n",
      "예측 요약 :  pb\n",
      "\n",
      "\n",
      "원문 : full bodied flavorful make medium cup smooth mellow cup java make tall alittle weak \n",
      "실제 요약 : excellent coffee \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : using entire sauce packet kill leaving salty greasy bottom carton otherwise noodles well made sauce reasonably well flavored quick easy brainer \n",
      "실제 요약 : noodles \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : yes real ones huge bag great price since little tiny bags pretty expensive love \n",
      "실제 요약 : yummy \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : tea incredible complexity flavor mind like fine wine fermented pu erh tea gets better age product surprised excellence \n",
      "실제 요약 : excellent tea \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : eating green black organic dark chocolate morning tea would never seen one currants hazelnuts amazing bars fresh could eat bars one day let far happy bites morning throughout day see something chocolatey tempted look forward know giving healthy treat \n",
      "실제 요약 : omg \n",
      "예측 요약 :  love this stuff\n",
      "\n",
      "\n",
      "원문 : low carb diet lost pounds tired eating meat time nervous splurge pasta came across product amazon cook minute two longer directions top full fat greek yogurt cheese one serving filling yummy definitely cures cravings subscribe save hubby son love \n",
      "실제 요약 : fantastic \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : family church gluten intolerant therefore cannot use regular bread bread mix great make family feel different everyone else mix super easy fix makes great loaf tasty bread glad found \n",
      "실제 요약 : bread mix \n",
      "예측 요약 :  best bread mix ever\n",
      "\n",
      "\n",
      "원문 : yummy kids loved cute story box \n",
      "실제 요약 : yummy \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : candy bears arrived fresh without damage love haribo gummi candy gold bears would recommend anyone enjoy \n",
      "실제 요약 : haribo gummi candy bears \n",
      "예측 요약 :  haribo gummi bears\n",
      "\n",
      "\n",
      "원문 : love stuff make granola add definitely buy \n",
      "실제 요약 : wow \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : second purchase better time one dented less water \n",
      "실제 요약 : pumpkin \n",
      "예측 요약 :  good product\n",
      "\n",
      "\n",
      "원문 : take bite recall oven tart satisfying boot \n",
      "실제 요약 : cherry pie in bar \n",
      "예측 요약 :  very good\n",
      "\n",
      "\n",
      "원문 : kids love things eating since little high school still eating flavor best eat well \n",
      "실제 요약 : what can be said about \n",
      "예측 요약 :  kids love them\n",
      "\n",
      "\n",
      "원문 : experimenting gluten free cookie recipes made added tablespoon extra margarine tablespoon soy milk also added extra mini chips bake slightly make sure let cool sheet rack really love \n",
      "실제 요약 : great and easy \n",
      "예측 요약 :  great cookies\n",
      "\n",
      "\n",
      "원문 : easy refreshing drink glass yummy change normal water drink love made honey strawberry acai blend delish \n",
      "실제 요약 : refreshing \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : noodles good hot enough good taste much like chilly \n",
      "실제 요약 : noodles \n",
      "예측 요약 :  good stuff\n",
      "\n",
      "\n",
      "원문 : line looking popcorn popper wedding gift amish country popcorn came match search family loves popcorn thought would try love popcorn little pieces popcorn almost hull free something really like popcorn kernels fresh purchasing product \n",
      "실제 요약 : yummy \n",
      "예측 요약 :  great popcorn\n",
      "\n",
      "\n",
      "원문 : nothing easier nothing better even beats grandmother white gravy recipe already peppered nothing mix water takes minute two highly recommend gravy mix disappoint \n",
      "실제 요약 : best white gravy \n",
      "예측 요약 :  the best\n",
      "\n",
      "\n",
      "원문 : ordered waffle maker father day dad traveled frequently belgium mix makes delicious waffles dad says better many belgium easy make easy add pecans top fruit cream think europe \n",
      "실제 요약 : as good as belgian waffles \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 60):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
